df1<-subset(df1, df1$ATS != 0)
summary(df1)
## Plot all distribution for tests and control points purchased
##
a_high <-ggplot(df1, aes(x = ATS, fill = Configuration_Name)) + geom_histogram(position="dodge")
a_high
##a_med <-ggplot(df1_med, aes(x = ATS, fill = Offer_Name)) + geom_histogram(position="dodge")
##a_med
## Plot log-transformed distribution for tests and control points purchased
##
b_high <-ggplot(df1, aes(x = log(ATS), fill = Configuration_Name)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Configuration_Name, fill=Configuration_Name))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
ad.test(subset(df1, df1$Configuration_Name=="Control")$ATS)
cvm.test(subset(df1, df1$Configuration_Name=="Control")$ATS)
shapiro.test(subset(df1, df1$Configuration_Name=="Control")$ATS)
ad.test(subset(df1, df1$Configuration_Name=="Test")$ATS)
cvm.test(subset(df1, df1$Configuration_Name=="Test")$ATS)
shapiro.test(subset(df1, df1$Configuration_Name=="Test")$ATS)
var(subset(df1, df1$Configuration_Name=="Test")$ATS)
var(subset(df1, df1$Configuration_Name=="Control")$ATS)
bartlett.test(df1$ATS~df1$Configuration_Name, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Configuration_Name, data=df1) #variance not significantly different
wilcox.test(df1$ATS~df1$Configuration_Name, conf.level=0.05) # 0.5182 not significant
t.test(log(df1$ATS)~df1$Configuration_Name, conf.level=0.05, var.equal=FALSE) # 0.3306 not significant
kruskal.test(ATS~Configuration_Name, data=df1) # 0.5182 not significant
### create matrix of data
con_h<-matrix(c(1665,1696,8137,8027), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.4085 insignificant
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Alaska/Jul_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
### Plot all the data by test and control Offer_Names ###
###                                                   ###
##subset data into high/med as well as mass
df1<-subset(df1, df1$Configuration_Name=="Test" |  df1$Configuration_Name=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Alaska/Jul_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
### Plot all the data by test and control Offer_Names ###
###                                                   ###
##subset data into high/med as well as mass
df1<-subset(df1, df1$Configuration_Name=="Test" |  df1$Configuration_Name=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
##summary(df1_med)
a_high <-ggplot(df1, aes(x = ATS, fill = Configuration_Name)) + geom_histogram(position="dodge")
a_high
##a_med <-ggplot(df1_med, aes(x = ATS, fill = Offer_Name)) + geom_histogram(position="dodge")
##a_med
## Plot log-transformed distribution for tests and control points purchased
##
b_high <-ggplot(df1, aes(x = log(ATS), fill = Configuration_Name)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Configuration_Name, fill=Configuration_Name))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Configuration_Name=="Control")$ATS)
cvm.test(subset(df1, df1$Configuration_Name=="Control")$ATS)
shapiro.test(subset(df1, df1$Configuration_Name=="Control")$ATS)
ad.test(subset(df1, df1$Configuration_Name=="Test")$ATS)
cvm.test(subset(df1, df1$Configuration_Name=="Test")$ATS)
shapiro.test(subset(df1, df1$Configuration_Name=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Configuration_Name=="Test")$ATS)
var(subset(df1, df1$Configuration_Name=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Configuration_Name, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Configuration_Name, data=df1) #variance not significantly different
wilcox.test(df1$ATS~df1$Configuration_Name, conf.level=0.05) # 0.5182 not significant
t.test(log(df1$ATS)~df1$Configuration_Name, conf.level=0.05, var.equal=FALSE) # 0. not significant
kruskal.test(ATS~Configuration_Name, data=df1) # 0.5182 not significant
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Alaska/Jul_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
##subset data into high/med as well as mass
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
## Plot all distribution for tests and control points purchased
##
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
##a_med <-ggplot(df1_med, aes(x = ATS, fill = Offer_Name)) + geom_histogram(position="dodge")
##a_med
## Plot log-transformed distribution for tests and control points purchased
##
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Test_Type=="Test")$ATS)
var(subset(df1, df1$Test_Type=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Test_Type, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Test_Type, data=df1) #variance not significantly different
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.2446 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.1269 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=TRUE) # 0.4821 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0.2446 not significant
### create matrix of data
con_h<-matrix(c(1986,7666,2003,7680), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.7046 insignificant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1399,6704,1466,6709), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.8645 insignificant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1399,8305,1466,8431), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.8645 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1399,6704,1466,6709), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.8645 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Alaska/Jul_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
### Plot all the data by test and control Offer_Names ###
###                                                   ###
##subset data into high/med as well as mass
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
##summary(df1_med)
## Plot all distribution for tests and control points purchased
##
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
##a_med <-ggplot(df1_med, aes(x = ATS, fill = Offer_Name)) + geom_histogram(position="dodge")
##a_med
## Plot log-transformed distribution for tests and control points purchased
##
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Test_Type=="Test")$ATS)
var(subset(df1, df1$Test_Type=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Test_Type, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Test_Type, data=df1) #variance not significantly different
## Step 3: Significance testing points purchased
## tests for location 35%
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.7586 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.4821 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0.7586 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=TRUE) # 0.4821 not significant
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Alaska/Jul_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
### Plot all the data by test and control Offer_Names ###
###                                                   ###
##subset data into high/med as well as mass
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
## Plot all distribution for tests and control points purchased
##
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
##a_med <-ggplot(df1_med, aes(x = ATS, fill = Offer_Name)) + geom_histogram(position="dodge")
##a_med
## Plot log-transformed distribution for tests and control points purchased
##
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
##b_med_log <- ggplot(df1_med, aes(x = log(ATS), fill = Offer_Name)) + geom_histogram(position="dodge")
##b_med_log
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Test_Type=="Test")$ATS)
var(subset(df1, df1$Test_Type=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Test_Type, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Test_Type, data=df1) #variance not significantly different
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.3253 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.1695 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=true) # 0.1695 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=TRUE) # 0.1695 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.1695 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0.3253 not significant
### create matrix of data
con_h<-matrix(c(1725,8033,1829,7947), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.2724 insignificant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1725,9944,1829,9998), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(720,1558,683,1543), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Alaska/Jul_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered Trasfer.csv", header=T)
## summarize data
summary(df1)
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Alaska/Jul_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered Transfer.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
### Plot all the data by test and control Offer_Names ###
###                                                   ###
##subset data into high/med as well as mass
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
## Plot all distribution for tests and control points purchased
##
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
##a_med <-ggplot(df1_med, aes(x = ATS, fill = Offer_Name)) + geom_histogram(position="dodge")
##a_med
## Plot log-transformed distribution for tests and control points purchased
##
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
## Plot average points purchased by test and control
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Test_Type=="Test")$ATS)
var(subset(df1, df1$Test_Type=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Test_Type, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Test_Type, data=df1) #variance not significantly different
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.3253 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.1695 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0.3253 not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1758,10514,1849,10543), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1758,8418,1849,8324), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1725,8033,1829,7949), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1758,8418,1849,8324), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
install.packages("Rserve")
library("Rserve")
Rserve(args='--vanilla')
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(1075,15170,1108,15116), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
