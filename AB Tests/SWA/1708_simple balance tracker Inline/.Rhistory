##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/Choice/Aug_17 BG Price Test")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
##subset data into high/med as well as mass
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
##summary(df1_med)
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
##a_med <-ggplot(df1_med, aes(x = ATS, fill = Offer_Name)) + geom_histogram(position="dodge")
##a_med
## Plot log-transformed distribution for tests and control points purchased
##
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
### Test for Significance between Test and Control Offer_Names ###
## Points Purchased ##
## Step 1: assess normality of distributions
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Test_Type=="Test")$ATS)
var(subset(df1, df1$Test_Type=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Test_Type, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Test_Type, data=df1) #variance not significantly different
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.3253 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.1695 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0.3253 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=TRUE) # 0.1695 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0. not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(121,457,485,1825), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(121,485,457,1825), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(121,485,457,1825), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
con_h
#run chi-square test
chisq.test(con_h)    # 0.06439 insignificant
## if p value <= 0.05 the result is significant
## if p value is > 0.05 and  <= 0.1 the result is marginally significant
## if p value > 0.1 then result is not significant
con_h
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/IHG/Aug_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/IHG/Aug_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/IHG/Aug_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
##subset data into high/med as well as mass
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
##summary(df1_med)
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Test_Type=="Test")$ATS)
var(subset(df1, df1$Test_Type=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Test_Type, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Test_Type, data=df1) #variance not significantly different
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.02845 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.04483 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=TRUE) # 0.04483 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0. not significant
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/IHG/Aug_Storefront")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
## This will filter out the sessions
df1<-subset(df1, df1$ATS != 0)
summary(df1)
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
##look at variance
##df1
var(subset(df1, df1$Test_Type=="Test")$ATS)
var(subset(df1, df1$Test_Type=="Control")$ATS)
## Bartlett Test
#raw data 35
bartlett.test(df1$ATS~df1$Test_Type, data=df1) #variance not significantly different
#log transformed data 35
bartlett.test(log(df1$ATS)~df1$Test_Type, data=df1) #variance not significantly different
## tests for location 35%
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.7816 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.8016 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0.7815 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.8365 not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(295,1086,2826,10956), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
con_h
chisq.test(con_h)    # 1 insignificant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(276,998,2485,9624), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
con_h
chisq.test(con_h)    # 1 insignificant
##load packages
library(ggplot2)
library(nortest)
library(car)
library(plyr)
library(coin)
## Set working directory
setwd("C:/Users/kelvin.ye/Google Drive/My Documents/Analytics-Kelvin/AB Tests/SWA/1708_simple balance tracker Inline")
##Load in data - I usually filter out sessions in Alteryx
df1<-read.csv("ATS_filtered.csv", header=T)
## summarize data
summary(df1)
## check data types
str(df1)
##subset data into high/med as well as mass
df1<-subset(df1, df1$Test_Type=="Test" |  df1$Test_Type=="Control")
##df1_med<-subset(df1, df1$Offer_Name=="Mass Control IHG" |  df1$Offer_Name=="Mass Test IHG")
df1<-subset(df1, df1$ATS != 0)
summary(df1)
a_high <-ggplot(df1, aes(x = ATS, fill = Test_Type)) + geom_histogram(position="dodge")
a_high
b_high <-ggplot(df1, aes(x = log(ATS), fill = Test_Type)) + geom_histogram(position="dodge")
b_high
p_high<-ggplot(df1, aes(y = ATS, x=Test_Type, fill=Test_Type))+ stat_summary(fun.y="mean", geom="bar")
p_high + labs(y="Average Points Purchased", x="Offer") + theme(axis.text.x = element_text(colour="black",size=14), axis.title.x=element_text(colour="black",size=14), axis.text.y = element_text(colour="black",size=14), axis.title.y=element_text(colour="black",size=14) )
#test Points normality high
ad.test(subset(df1, df1$Test_Type=="Control")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Control")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Control")$ATS)
ad.test(subset(df1, df1$Test_Type=="Test")$ATS)
cvm.test(subset(df1, df1$Test_Type=="Test")$ATS)
shapiro.test(subset(df1, df1$Test_Type=="Test")$ATS)
wilcox.test(df1$ATS~df1$Test_Type, conf.level=0.05) # 0.1443 not significant
t.test(log(df1$ATS)~df1$Test_Type, conf.level=0.05, var.equal=FALSE) # 0.3181 not significant
kruskal.test(ATS~Test_Type, data=df1) # 0.1443 not significant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(2607,10660,11024,43890), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
con_h
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(2607,11024,10660,43890), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
con_h
chisq.test(con_h)    # 0.3209 insignificant
#########################################
###### Sample Chi Square ###################
#########################################
### create matrix of data
con_h<-matrix(c(121,485,457,1825), ncol=2, byrow=TRUE)
#label the rows and columns
colnames(con_h)<-c("test","control")
rownames(con_h)<-c("transactions", "audience")
#convert object to a contingency table
con_h<-as.table(con_h)
con_h
